{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89f7f1a-1df5-475e-943f-8e823f8b69a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: ipdb in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.13.13)\n",
      "Requirement already satisfied: ipython>=7.31.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipdb) (8.12.3)\n",
      "Requirement already satisfied: tomli in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipdb) (2.2.1)\n",
      "Requirement already satisfied: decorator in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipdb) (5.1.1)\n",
      "Requirement already satisfied: backcall in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
      "Requirement already satisfied: appnope in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.1.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.31.1->ipdb) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.31.1->ipdb) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.31.1->ipdb) (0.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: jupyter in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (7.3.2)\n",
      "Requirement already satisfied: jupyter-console in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (4.3.4)\n",
      "Requirement already satisfied: appnope in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (8.12.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "Requirement already satisfied: pygments in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-console->jupyter) (2.18.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (6.4.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (3.1.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (49.2.1)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (0.10.1)\n",
      "Requirement already satisfied: nbformat>=5.7 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter) (4.12.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: anyio in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.5.2)\n",
      "Requirement already satisfied: certifi in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyterlab->jupyter) (3.20.2)\n",
      "Requirement already satisfied: backcall in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: pickleshare in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.20.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20241206)\n",
      "Requirement already satisfied: wandb in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: eval-type-backport in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (0.2.2)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (5.29.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (2.10.4)\n",
      "Requirement already satisfied: pyyaml in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (2.18.0)\n",
      "Requirement already satisfied: setproctitle in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (49.2.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: datetime in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (5.5)\n",
      "Requirement already satisfied: zope.interface in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from datetime) (7.2)\n",
      "Requirement already satisfied: pytz in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from datetime) (2024.2)\n",
      "Requirement already satisfied: setuptools in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from zope.interface->datetime) (49.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install ipdb\n",
    "!pip install tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install jupyter\n",
    "!pip install wandb\n",
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ab5601-d66a-46b3-b27c-636236adfd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in /Users/saakla/miniconda/envs/llmdemo/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957cf4ec-7454-45fd-9e4f-02ac7419f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "\n",
    "import os, sys\n",
    "import ipdb\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import platform, shutil #detect platform type\n",
    "import requests, zipfile, io\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#tokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "# improve performance for ampere arch\n",
    "#torch.backends.cuda.matmpl.allow_tf32 = True\n",
    "#torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Empty GPU cache memory\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2432d823-39e4-40f9-ad75-c8b7a83fa165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files using python\n"
     ]
    }
   ],
   "source": [
    "files_url = \"https://ideami.com/llm_train\"\n",
    "print(\"Downloading files using python\")\n",
    "response = requests.get(files_url)\n",
    "zipfile.ZipFile(io.BytesIO(response.content)).extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3374752-a673-452b-9001-26543ddec563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "batch_size = 8 # 8 to 128 based on available memory\n",
    "context = 512\n",
    "embed_size = 384\n",
    "n_layers = 7 # layers in the tranformer model\n",
    "n_heads = 7 # Number of heads\n",
    "head_size = 54\n",
    "BIAS = True\n",
    "\n",
    "# Hyperparameter\n",
    "lr = 3e-4 #learning rate\n",
    "dropout = 0.05 # L2 regularization (drop couple of neurons, to reduce over fitting)\n",
    "weight_decay = 0.01\n",
    "grad_clip = 1.0\n",
    "\n",
    "# training parameters\n",
    "train_iters = 100000\n",
    "eval_interval = 50\n",
    "eval_iteration = 3\n",
    "compile = False\n",
    "checkpoint_dir = 'models/'\n",
    "checkpoint_fn = 'latest.pt'\n",
    "checkpoint_load_fn = 'latest.pt'\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# Mode\n",
    "inference = False\n",
    "\n",
    "load_pretrained = False\n",
    "\n",
    "# DEVICE\n",
    "#device = \"cuda\" if torch.cuda_is_available() else \"cpu\"\n",
    "#print(\"device: you will be using: \",device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a219ef41-7285-42be-97f8-8102237e28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "wandb_log = True\n",
    "wandb_project = \"llm1\"\n",
    "wandb_run_name = \"llm1-\"+datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "if wandb_log:\n",
    "    import wandb\n",
    "    wandb.init(project=wandb_project, name=wandb_run_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1f80c7-8f83-410c-b4b7-9421f8d01a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms.\n",
      "For example, there are objects in two groups (as shown on the right). The objects are various shapes, where one group has 3 of them while the other has 2. When the two groups combine into one, the overall amount (sum) of the shapes become 5.\n",
      "\n",
      "Vertical Addition\n",
      "\n",
      "The animation above demonstrate\n"
     ]
    }
   ],
   "source": [
    "with open('wiki.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[30000:30300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d105ab-0c12-4986-857a-4b1a0f9180ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab_size: 4096\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='wiki_tokenizer.model')\n",
    "vocab_size = sp.get_piece_size()\n",
    "print(f\"tokenizer vocab_size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019dee09-5de6-4ba7-acf8-70da8f08c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2686, 698, 265, 261, 684]\n",
      "once upon a time\n"
     ]
    }
   ],
   "source": [
    "encode = lambda s : sp.Encode(s)\n",
    "decode = lambda l : sp.Decode(l)\n",
    "\n",
    "print(encode(\"once upon a time\"))\n",
    "print(decode(encode(\"once upon a time\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88dfab4-2ccf-4487-a757-eedd476804c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"encoded_data.pt\"):\n",
    "    print(\"Loading data\")\n",
    "    data = torch.load(\"encoded_data.pt\")\n",
    "else:\n",
    "    data = torch.tensor(encode(text),dtype=torch.long)\n",
    "    torch.save(data, 'encoded_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90de8f7c-d614-4d0d-ba39-4d834ab2e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 59.21 Million | Training: 53.29\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "\n",
    "data_size = len(data)\n",
    "spl = int(0.9*data_size)\n",
    "train_data = data[:spl]\n",
    "val_data = data[spl:]\n",
    "print(f'total data: {data_size/1e6:.2f} Million | Training: {len(train_data)/1e6:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c149883-4a18-4011-9faa-1225941ac3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "tensor([ 569,  324, 4064, 1276,  298,  317,  266, 1426, 4060,  289])\n",
      "tensor([ 324, 4064, 1276,  298,  317,  266, 1426, 4060,  289,  324])\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    inds = torch.randint(len(data)-context, (batch_size,))\n",
    "    x = torch.stack([data[i: i+context] for i in inds]) #(batch size, seq length)\n",
    "    y = torch.stack([data[i+1: i+context+1] for i in inds]) #(BS, SL)\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x,y\n",
    "\n",
    "x,y=get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print(x[0][:10])\n",
    "print(y[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b64ce20-782a-4a70-81e8-0e281b08ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM Model ###\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_size) # eg 4096 x 384\n",
    "        self.positions = nn.Embedding(context, embed_size) # e.g 512 x 384\n",
    "        self.blocks = nn.Sequential(*[Block(n_heads) for _ in range(n_layers)])\n",
    "        self.ln = nn.LayerNorm(embed_size)\n",
    "        self.final_linear = nn.Linear(embed_size, vocab_size, bias=BIAS) # eg 384, 4096\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    #parameter initializatin\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, input, targets=None):\n",
    "        # BS = batch size, SL = sequence or context length\n",
    "        loss = None\n",
    "        BS, SL = input.shape # BS, SL\n",
    "        emb = self.embeddings(input) # bsxslx 384\n",
    "        pos = self.positions(torch.arange(SL, device=device)) #SL * 384\n",
    "        x = emb + pos \n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.final_linear(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            BS, SL, VS = logits.shape #BS X SL X 4096\n",
    "            logits = logits.view(BS*SL, VS)\n",
    "            targets = targets.view(BS*SL)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "            # manual calculation\n",
    "            counts = logits.exp()\n",
    "            prob = counts/counts.sum(-1, keepdim=True)\n",
    "            loss2 = -prob[torch.arange(BS*SL),targets].log().mean()\n",
    "            # target[3] = 329\n",
    "            # information i = -log p(X)\n",
    "\n",
    "            if(not torch.allclose(loss, loss2)):\n",
    "                print(f\"[loss diff] pytorch:{loss.item()} Manual:{loss2.item()}\")\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    # Generate a new sample\n",
    "    def generate(self, input, max=500):\n",
    "        for _ in range(max):\n",
    "            input = input[:,-context:] # (1, input len until max of SL)\n",
    "            logits, _ = self(input) # (1, input length, 4096)\n",
    "            logits = logits[:,-1, :] # pick last probability\n",
    "            probs = F.softmax(logits, dim=-1) #(1, 4096)\n",
    "            next = torch.multinomial(probs, num_samples=1)\n",
    "            input = torch.cat((input, next), dim=1)\n",
    "        return input\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d2955e1-da20-4fd5-848d-582a176445f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = embed_size//n_heads\n",
    "        self.ma = MultiHead(n_heads, head_size)\n",
    "        self.feed_forward = ForwardLayer(embed_size)\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + self.ma(self.ln1(x))\n",
    "        x = x + self.feed_forward(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c989aa40-bab9-4798-89e4-7a2e5b3e3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardLayer(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(embed_size, 6*embed_size, bias=BIAS),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(6*embed_size, embed_size, bias=BIAS),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e902a7ee-c54f-43cc-a202-1eb5df8c1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self,n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.combine = nn.Linear(head_size * n_heads, embed_size, bias=BIAS) # 378, 384\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        # head output (BS, SL, head_size)\n",
    "        x = self.combine(x) # (BS, SL, 384)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a833e54-42c4-448f-856a-7057152375f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.queries = nn.Linear(embed_size, head_size, bias=BIAS)\n",
    "        self.keys = nn.Linear(embed_size, head_size, bias=BIAS)\n",
    "        self.values = nn.Linear(embed_size, head_size, bias=BIAS)\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context, context)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        BS, SL, VS = x.shape\n",
    "        q = self.queries(x) # BS, SL, 54 (54 = 384/7, 7 heads)\n",
    "        k = self.keys(x) # BS, SL, 54 (54 = 384/7, 7 heads)\n",
    "        v = self.values(x) # BS, SL, 54 (54 = 384/7, 7 heads)\n",
    "        \n",
    "        attn_w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # BS, SL, SL\n",
    "        attn_w = attn_w.masked_fill(self.tril[:SL, :SL]==0, float('-inf'))\n",
    "        attn_w = F.softmax(attn_w, dim=-1) # BS, SL, SL\n",
    "\n",
    "        x = attn_w @ v # BS, SL, 54\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95c45948-54da-4332-af6b-d5f302c505e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "tensor([4065, 4065, 4089,  197,  163,  229,  131,  150,  962, 4031])\n",
      "tensor([4065, 4089,  197,  163,  229,  131,  150,  962, 4031, 4056])\n"
     ]
    }
   ],
   "source": [
    "x,y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print(x[0][:10])\n",
    "print(y[0][:10])\n",
    "\n",
    "model = GPT()\n",
    "model = model.to(dtype)\n",
    "model = model.to(device)\n",
    "\n",
    "# logits, loss, loss2 = model(x,y)\n",
    "# print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50efe0a3-f7dc-4403-a5a0-d9f75bd24b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "torch.Size([8, 512, 54]) torch.Size([8, 512, 54]) torch.Size([8, 512, 54])\n",
      "tensor([-0.77, -1.81,  0.95, -0.01,  0.45, -0.27,  0.19, -0.19, -0.42,  0.24,\n",
      "         0.26,  0.73,  0.56, -0.48, -0.29, -0.10,  0.03, -0.65, -2.00,  0.57,\n",
      "        -0.03,  0.67,  0.26, -0.18, -0.49,  0.50, -0.69,  1.38,  0.24,  1.02,\n",
      "         1.46, -1.58,  0.50, -0.20, -0.51,  0.79, -0.55, -0.42,  0.32, -0.33,\n",
      "         0.89, -0.47,  0.48, -1.39, -0.08, -0.81, -0.62, -1.11,  0.87,  0.19,\n",
      "         0.19, -1.94,  0.79,  0.23], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# deep dive attention calculations\n",
    "x,y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "# print(x[0][:10])\n",
    "# print(y[0][:10])\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "embeddings = nn.Embedding(vocab_size, embed_size).to(device) # eg 4096 x 384\n",
    "positions = nn.Embedding(context, embed_size).to(device) # e.g 512 x 384\n",
    "queries = nn.Linear(embed_size, head_size, bias=BIAS).to(device)\n",
    "keys = nn.Linear(embed_size, head_size, bias=BIAS).to(device)\n",
    "values = nn.Linear(embed_size, head_size, bias=BIAS).to(device)\n",
    "tril = torch.tril(torch.ones(context,context)).to(device)\n",
    "\n",
    "emb = embeddings(x)\n",
    "pos = positions(torch.arange(context, device=device))\n",
    "x = emb + pos\n",
    "\n",
    "q = queries(x)\n",
    "k = keys(x)\n",
    "v = values(x)\n",
    "print(q.shape, k.shape, v.shape)\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "#torch.set_printoptions(precision=4, threshold=1000, edgeitems=3, linewidth=80, profile='default', sci_mode=True)\n",
    "print(q[0][0])\n",
    "\n",
    "attn_w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # BS, SL, SL\n",
    "attn_w = attn_w.masked_fill(tril[:context, :context]==0, float('-inf'))\n",
    "attn_w = F.softmax(attn_w, dim=-1) # BS, SL, SL\n",
    "\n",
    "x = attn_w @ v # BS, SL, 54\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af41d643-1e51-45c3-8dfa-dc41caef3db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.70,  0.98,  0.11, -0.03,  0.24, -0.55,  0.03, -0.06,  0.17, -0.06,\n",
      "         1.18,  0.95,  0.17, -0.93, -0.07,  0.03, -1.21, -0.55, -0.15,  0.36,\n",
      "        -0.19, -0.35, -0.05,  0.81, -1.22,  1.48,  1.48,  0.37,  0.18,  0.60,\n",
      "         0.18,  0.97,  0.10,  0.62, -1.21, -0.61, -0.99,  1.08, -0.97, -1.94,\n",
      "        -1.63,  1.64,  0.54,  0.22, -0.32, -0.66, -0.86, -0.54, -0.11, -0.11,\n",
      "        -0.50, -0.25,  0.98, -2.31], grad_fn=<SelectBackward0>) tensor([ 0.48, -1.19, -0.78, -0.06, -0.91,  0.58,  0.46,  1.25, -1.69, -1.71,\n",
      "         0.24, -1.23, -0.75, -0.82, -0.57, -0.01,  0.81, -0.74, -1.35,  0.36,\n",
      "         0.03,  0.77, -0.90,  0.56,  0.67,  1.26, -1.55, -0.22, -0.31,  0.35,\n",
      "        -1.09,  0.11,  0.11,  0.23,  0.94,  0.98, -1.27,  0.31,  1.37,  0.89,\n",
      "         1.11,  0.20, -0.51, -0.71,  1.00, -0.00,  0.90, -1.37,  0.50, -0.71,\n",
      "         0.21,  0.63,  0.46,  0.51], grad_fn=<SelectBackward0>)\n",
      "tensor(-8.98, grad_fn=<DotBackward0>)\n",
      "tensor(-8.98, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# understand attn matrix\n",
    "\n",
    "full = q @ k.transpose(-2, -1)\n",
    "# compare 5th token to 3rd token in a 54 dim\n",
    "a = q[0][5]\n",
    "b = k.transpose(-2,-1)[0,:,5]\n",
    "print(a,b)\n",
    "c = torch.dot(a,b)\n",
    "# compare the token with the full matrix, comparing the aligment b/w tokens\n",
    "print(c)\n",
    "print(full[0][5][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3944fcc1-442b-4da7-af8b-337805c52c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 512]) torch.Size([8, 512, 54])\n",
      "tensor([-0.04,  0.24,  0.16, -0.27,  0.36,  0.47,  0.35, -0.41, -0.24, -0.58,\n",
      "        -0.05,  0.07,  0.21, -0.06,  0.05,  0.09, -0.27, -0.01,  0.06, -0.15,\n",
      "         0.56, -0.80, -0.08,  0.58, -0.09,  0.51, -0.46, -0.28, -0.37,  0.32,\n",
      "        -0.23, -0.05,  0.54, -0.15,  0.65, -0.22, -0.47, -0.55, -0.13,  0.10,\n",
      "         0.48, -0.18,  0.75, -0.45, -0.26,  0.23,  0.28,  0.21,  0.07, -0.14,\n",
      "         0.34, -0.04,  0.21,  0.07], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.04,  0.24,  0.16, -0.27,  0.36,  0.47,  0.35, -0.41, -0.24, -0.58,\n",
      "        -0.05,  0.07,  0.21, -0.06,  0.05,  0.09, -0.27, -0.01,  0.06, -0.15,\n",
      "         0.56, -0.80, -0.08,  0.58, -0.09,  0.51, -0.46, -0.28, -0.37,  0.32,\n",
      "        -0.23, -0.05,  0.54, -0.15,  0.65, -0.22, -0.47, -0.55, -0.13,  0.10,\n",
      "         0.48, -0.18,  0.75, -0.45, -0.26,  0.23,  0.28,  0.21,  0.07, -0.14,\n",
      "         0.34, -0.04,  0.21,  0.07], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "# understand the updating of the v content (values)\n",
    "print(attn_w.shape, v.shape)\n",
    "\n",
    "print(x[0][7])\n",
    "\n",
    "# check the 7 token\n",
    "attn_scores2 = attn_w[0, 7, :] #shape [512]\n",
    "# initialize tensor to store the result\n",
    "result = torch.zeros(54)\n",
    "# compute the do product for the each column in the v for the first token in the first batch\n",
    "for i in range(54):\n",
    "    result[i] = torch.dot(attn_scores2, v[0,:,i])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60c668ba-f076-429f-8f78-bd9ee9f97ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "tensor([ 653, 1828,  824,  845,  870, 1069, 4031, 4062, 4051,  343])\n",
      "tensor([1828,  824,  845,  870, 1069, 4031, 4062, 4051,  343,  528])\n",
      "8.4375\n"
     ]
    }
   ],
   "source": [
    "x,y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print(x[0][:10])\n",
    "print(y[0][:10])\n",
    "\n",
    "model = GPT()\n",
    "model = model.to(dtype)\n",
    "model = model.to(device)\n",
    "logits, loss = model(x,y)\n",
    "# logits, loss, loss2 = model(x,y)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67847fe6-9c48-4a92-80fa-e6ae8a0f8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " occur box name� War kept Christianitive other workingachesince changeask Columb Phil problem comes toiller Michmonddela size education Kentamage Virginiava Super de Sm Indian\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate_sample(input):\n",
    "    t1 = torch.tensor(encode(input), dtype=torch.long, device=device)\n",
    "    t1 = t1[None, :] #(1, [size of the ids])\n",
    "    newgen= model.generate(t1, max=64)[0].tolist()\n",
    "    result=decode(newgen)\n",
    "    print(f\"{result}\")\n",
    "\n",
    "generate_sample(\"Once upon a time\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a3c8a52-0bc6-4e7f-a811-351d4ad2ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.837954 Million parameters\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "\n",
    "model = GPT()\n",
    "model = model.to(dtype)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "if compile:\n",
    "    print(\"torch :: compiling model\")\n",
    "    model = torch.compile(model)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, \"Million parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82475128-1ac0-46cc-bcb7-1a2af75ba63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "{'train': 8.4375, 'eval': 8.4375}\n"
     ]
    }
   ],
   "source": [
    "# calculate loss average\n",
    "@torch.no_grad()\n",
    "def calculate_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train','eval']:\n",
    "        l = torch.zeros(eval_iteration)\n",
    "        for i in range(eval_iteration):\n",
    "            x,y = get_batch(split)\n",
    "            _,loss = model(x,y)\n",
    "            l[i]=loss\n",
    "        out[split]=l.mean().item()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "l = calculate_loss()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f797629-aa86-4866-bdaf-33baccc4f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the optimizer\n",
    "\n",
    "p_dict = {p_name: p for p_name, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "weight_decay_p = [p for n,p in p_dict.items() if p.dim() >=2]\n",
    "no_weight_decay_p = [p for n,p in p_dict.items() if p.dim() < 2]\n",
    "\n",
    "optimizer_groups = [\n",
    "    {'params':weight_decay_p,'weight_decay':weight_decay},\n",
    "    {'params':no_weight_decay_p,'weight_decay':0.0},\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_groups, lr=lr, betas=(0.9, 0.99))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_iters, eta_min=lr/10)\n",
    "\n",
    "start_iteration = 0\n",
    "best_val_loss = float('inf') # track the validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8faf3adf-6789-49b8-8301-00627feb4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading checkpoints\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    print(\"LLM - Loading model\")\n",
    "    # Add map_location parameter to load the model on CPU\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    iteration = checkpoint['iteration']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"loaded iter {iteration} with loss {loss}\")\n",
    "    return iteration, loss\n",
    "\n",
    "if os.path.exists(f\"{checkpoint_dir}/{checkpoint_load_fn}\") and load_pretrained:\n",
    "    start_iteration, loss = load_checkpoint(checkpoint_dir+checkpoint_load_fn)\n",
    "    best_val_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4456e476-5602-4833-a999-4bd5d822ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "if inference == True:\n",
    "    model.eval()\n",
    "    while True:\n",
    "        qs = input(\"Enter text (q to quit):\")\n",
    "        if qs == \"\":\n",
    "            continue\n",
    "        if qs == \"q\":\n",
    "            break\n",
    "        generate_sample(qs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed5505ee-69e6-41bb-a18e-15bcee448df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "\n",
      "0: train loss: 8.4375/ val loss: 8.4375\n",
      "Once upon a time causedersey pain regionher port Rob Jer Jr over�ouncada Don Pakistan Marthy school that mer community common mag muchransynasty British Cle problemsological occur neededatives just� skin housir using Russia ratherme contro known partic askound story Wrestore published Minn tr campW minister center Alsoionalrdella Christian Soviet blue\n",
      "[Checkpoint]: save with loss:  8.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                | 0/100000 [17:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory released\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saakla/miniconda/envs/llmdemo/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(start_iteration, train_iters)):\n",
    "        xb, yb = get_batch(\"train\")\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "        if (i % eval_interval == 0 or i == train_iters-1):\n",
    "            l = calculate_loss()\n",
    "            print(f\"\\n{i}: train loss: {l['train']}/ val loss: {l['eval']}\")\n",
    "            generate_sample(\"Once upon a time\")\n",
    "\n",
    "            if l['eval'] < best_val_loss:\n",
    "                best_val_loss = l['eval']\n",
    "                print(\"[Checkpoint]: save with loss: \", best_val_loss)\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss' : best_val_loss,\n",
    "                    'iteration': i,\n",
    "                }, checkpoint_dir + checkpoint_fn)\n",
    "\n",
    "\n",
    "            if wandb_log:\n",
    "                wandb.log({\n",
    "                    \"loss/train\":l['train'],\n",
    "                    \"loss/val\" : l['eval'],\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                },\n",
    "                step = i)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=grap_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "\n",
    "    if wandb_log:\n",
    "        wandb.finish()\n",
    "\n",
    "except keyboardInterrupt:\n",
    "    print(\"training interrupted, cleaning up..\")\n",
    "\n",
    "finally:\n",
    "    # release gpu memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU memory released\")\n",
    "    sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a47573-9ee5-40a2-8e6b-51bc0b4a1a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
