{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89f7f1a-1df5-475e-943f-8e823f8b69a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: ipdb in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.13.13)\n",
      "Requirement already satisfied: ipython>=7.31.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipdb) (8.12.3)\n",
      "Requirement already satisfied: tomli in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipdb) (2.2.1)\n",
      "Requirement already satisfied: decorator in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipdb) (5.1.1)\n",
      "Requirement already satisfied: backcall in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
      "Requirement already satisfied: appnope in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.31.1->ipdb) (0.1.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.31.1->ipdb) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.31.1->ipdb) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.31.1->ipdb) (0.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: jupyter in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (7.3.2)\n",
      "Requirement already satisfied: jupyter-console in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter) (4.3.4)\n",
      "Requirement already satisfied: appnope in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (8.12.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "Requirement already satisfied: pygments in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-console->jupyter) (2.18.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (6.4.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (3.1.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (49.2.1)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (0.10.1)\n",
      "Requirement already satisfied: nbformat>=5.7 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter) (4.12.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: anyio in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.5.2)\n",
      "Requirement already satisfied: certifi in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyterlab->jupyter) (3.20.2)\n",
      "Requirement already satisfied: backcall in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: pickleshare in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.20.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20241206)\n",
      "Requirement already satisfied: wandb in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: eval-type-backport in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (0.2.2)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (5.29.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (2.10.4)\n",
      "Requirement already satisfied: pyyaml in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (2.18.0)\n",
      "Requirement already satisfied: setproctitle in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (49.2.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: datetime in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (5.5)\n",
      "Requirement already satisfied: zope.interface in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from datetime) (7.2)\n",
      "Requirement already satisfied: pytz in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from datetime) (2024.2)\n",
      "Requirement already satisfied: setuptools in /Users/saakla/.pyenv/versions/3.8.7/lib/python3.8/site-packages (from zope.interface->datetime) (49.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install ipdb\n",
    "!pip install tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install jupyter\n",
    "!pip install wandb\n",
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ab5601-d66a-46b3-b27c-636236adfd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in /Users/saakla/miniconda/envs/llmdemo/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957cf4ec-7454-45fd-9e4f-02ac7419f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "\n",
    "import os, sys\n",
    "import ipdb\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import platform, shutil #detect platform type\n",
    "import requests, zipfile, io\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#tokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "# improve performance for ampere arch\n",
    "#torch.backends.cuda.matmpl.allow_tf32 = True\n",
    "#torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Empty GPU cache memory\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2432d823-39e4-40f9-ad75-c8b7a83fa165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files using python\n"
     ]
    }
   ],
   "source": [
    "files_url = \"https://ideami.com/llm_train\"\n",
    "print(\"Downloading files using python\")\n",
    "response = requests.get(files_url)\n",
    "zipfile.ZipFile(io.BytesIO(response.content)).extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3374752-a673-452b-9001-26543ddec563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "batch_size = 8 # 8 to 128 based on available memory\n",
    "context = 512\n",
    "embed_size = 384\n",
    "n_layers = 7 # layers in the tranformer model\n",
    "n_heads = 7 # Number of heads\n",
    "head_size = 54\n",
    "BIAS = True\n",
    "\n",
    "# Hyperparameter\n",
    "lr = 3e-4 #learning rate\n",
    "dropout = 0.05 # L2 regularization (drop couple of neurons, to reduce over fitting)\n",
    "weight_decay = 0.01\n",
    "grad_clip = 1.0\n",
    "\n",
    "# training parameters\n",
    "train_iters = 100000\n",
    "eval_interval = 50\n",
    "eval_iteration = 3\n",
    "compile = False\n",
    "checkpoint_dir = 'models/'\n",
    "checkpoint_fn = 'latest.pt'\n",
    "checkpoint_load_fn = 'latest.pt'\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# Mode\n",
    "inference = False\n",
    "\n",
    "load_pretrained = False\n",
    "\n",
    "# DEVICE\n",
    "#device = \"cuda\" if torch.cuda_is_available() else \"cpu\"\n",
    "#print(\"device: you will be using: \",device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a219ef41-7285-42be-97f8-8102237e28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "wandb_log = True\n",
    "wandb_project = \"llm1\"\n",
    "wandb_run_name = \"llm1-\"+datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "if wandb_log:\n",
    "    import wandb\n",
    "    wandb.init(project=wandb_project, name=wandb_run_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1f80c7-8f83-410c-b4b7-9421f8d01a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms.\n",
      "For example, there are objects in two groups (as shown on the right). The objects are various shapes, where one group has 3 of them while the other has 2. When the two groups combine into one, the overall amount (sum) of the shapes become 5.\n",
      "\n",
      "Vertical Addition\n",
      "\n",
      "The animation above demonstrate\n"
     ]
    }
   ],
   "source": [
    "with open('wiki.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[30000:30300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d105ab-0c12-4986-857a-4b1a0f9180ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab_size: 4096\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='wiki_tokenizer.model')\n",
    "vocab_size = sp.get_piece_size()\n",
    "print(f\"tokenizer vocab_size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019dee09-5de6-4ba7-acf8-70da8f08c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2686, 698, 265, 261, 684]\n",
      "once upon a time\n"
     ]
    }
   ],
   "source": [
    "encode = lambda s : sp.Encode(s)\n",
    "decode = lambda l : sp.Decode(l)\n",
    "\n",
    "print(encode(\"once upon a time\"))\n",
    "print(decode(encode(\"once upon a time\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88dfab4-2ccf-4487-a757-eedd476804c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"encoded_data.pt\"):\n",
    "    print(\"Loading data\")\n",
    "    data = torch.load(\"encoded_data.pt\")\n",
    "else:\n",
    "    data = torch.tensor(encode(text),dtype=torch.long)\n",
    "    torch.save(data, 'encoded_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90de8f7c-d614-4d0d-ba39-4d834ab2e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 59.21 Million | Training: 53.29\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "\n",
    "data_size = len(data)\n",
    "spl = int(0.9*data_size)\n",
    "train_data = data[:spl]\n",
    "val_data = data[spl:]\n",
    "print(f'total data: {data_size/1e6:.2f} Million | Training: {len(train_data)/1e6:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c149883-4a18-4011-9faa-1225941ac3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "tensor([ 569,  324, 4064, 1276,  298,  317,  266, 1426, 4060,  289])\n",
      "tensor([ 324, 4064, 1276,  298,  317,  266, 1426, 4060,  289,  324])\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    inds = torch.randint(len(data)-context, (batch_size,))\n",
    "    x = torch.stack([data[i: i+context] for i in inds]) #(batch size, seq length)\n",
    "    y = torch.stack([data[i+1: i+context+1] for i in inds]) #(BS, SL)\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x,y\n",
    "\n",
    "x,y=get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print(x[0][:10])\n",
    "print(y[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b64ce20-782a-4a70-81e8-0e281b08ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM Model ###\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_size) # eg 4096 x 384\n",
    "        self.positions = nn.Embedding(context, embed_size) # e.g 512 x 384\n",
    "        self.blocks = nn.Sequential(*[Block(n_heads) for _ in range(n_layers)])\n",
    "        self.ln = nn.LayerNorm(embed_size)\n",
    "        self.final_linear = nn.Linear(embed_size, vocab_size, bias=BIAS) # eg 384, 4096\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    #parameter initializatin\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, input, targets=None):\n",
    "        # BS = batch size, SL = sequence or context length\n",
    "        loss = None\n",
    "        BS, SL = input.shape # BS, SL\n",
    "        emb = self.embeddings(input) # bsxslx 384\n",
    "        pos = self.positions(torch.arange(SL, device=device)) #SL * 384\n",
    "        x = emb + pos \n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.final_linear(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            BS, SL, VS = logits.shape #BS X SL X 4096\n",
    "            logits = logits.view(BS*SL, VS)\n",
    "            targets = targets.view(BS*SL)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "            # manual calculation\n",
    "            counts = logits.exp()\n",
    "            prob = counts/counts.sum(-1, keepdim=True)\n",
    "            loss2 = -prob[torch.arange(BS*SL),targets].log().mean()\n",
    "            # target[3] = 329\n",
    "            # information i = -log p(X)\n",
    "\n",
    "            if(not torch.allclose(loss, loss2)):\n",
    "                print(f\"[loss diff] pytorch:{loss.item()} Manual:{loss2.item()}\")\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    # Generate a new sample\n",
    "    def generate(self, input, max=500):\n",
    "        for _ in range(max):\n",
    "            input = input[:,-context:] # (1, input len until max of SL)\n",
    "            logits, _ = self(input) # (1, input length, 4096)\n",
    "            logits = logits[:,-1, :] # pick last probability\n",
    "            probs = F.softmax(logits, dim=-1) #(1, 4096)\n",
    "            next = torch.multinomial(probs, num_samples=1)\n",
    "            input = torch.cat((input, next), dim=1)\n",
    "        return input\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d2955e1-da20-4fd5-848d-582a176445f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = embed_size//n_heads\n",
    "        self.ma = MultiHead(n_heads, head_size)\n",
    "        self.feed_forward = ForwardLayer(embed_size)\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + self.ma(self.ln1(x))\n",
    "        x = x + self.feed_forward(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c989aa40-bab9-4798-89e4-7a2e5b3e3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardLayer(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(embed_size, 6*embed_size, bias=BIAS),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(6*embed_size, embed_size, bias=BIAS),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e902a7ee-c54f-43cc-a202-1eb5df8c1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self,n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.combine = nn.Linear(head_size * n_heads, embed_size, bias=BIAS) # 378, 384\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        # head output (BS, SL, head_size)\n",
    "        x = self.combine(x) # (BS, SL, 384)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a833e54-42c4-448f-856a-7057152375f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.queries = nn.Linear(embed_size, head_size, bias=BIAS)\n",
    "        self.keys = nn.Linear(embed_size, head_size, bias=BIAS)\n",
    "        self.values = nn.Linear(embed_size, head_size, bias=BIAS)\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context, context)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        BS, SL, VS = x.shape\n",
    "        q = self.queries(x) # BS, SL, 54 (54 = 384/7, 7 heads)\n",
    "        k = self.keys(x) # BS, SL, 54 (54 = 384/7, 7 heads)\n",
    "        v = self.values(x) # BS, SL, 54 (54 = 384/7, 7 heads)\n",
    "        \n",
    "        attn_w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # BS, SL, SL\n",
    "        attn_w = attn_w.masked_fill(self.tril[:SL, :SL]==0, float('-inf'))\n",
    "        attn_w = F.softmax(attn_w, dim=-1) # BS, SL, SL\n",
    "\n",
    "        x = attn_w @ v # BS, SL, 54\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95c45948-54da-4332-af6b-d5f302c505e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "tensor([4065, 4065, 4089,  197,  163,  229,  131,  150,  962, 4031])\n",
      "tensor([4065, 4089,  197,  163,  229,  131,  150,  962, 4031, 4056])\n"
     ]
    }
   ],
   "source": [
    "x,y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print(x[0][:10])\n",
    "print(y[0][:10])\n",
    "\n",
    "model = GPT()\n",
    "model = model.to(dtype)\n",
    "model = model.to(device)\n",
    "\n",
    "# logits, loss, loss2 = model(x,y)\n",
    "# print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50efe0a3-f7dc-4403-a5a0-d9f75bd24b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "torch.Size([8, 512, 54]) torch.Size([8, 512, 54]) torch.Size([8, 512, 54])\n",
      "tensor([-0.77, -1.81,  0.95, -0.01,  0.45, -0.27,  0.19, -0.19, -0.42,  0.24,\n",
      "         0.26,  0.73,  0.56, -0.48, -0.29, -0.10,  0.03, -0.65, -2.00,  0.57,\n",
      "        -0.03,  0.67,  0.26, -0.18, -0.49,  0.50, -0.69,  1.38,  0.24,  1.02,\n",
      "         1.46, -1.58,  0.50, -0.20, -0.51,  0.79, -0.55, -0.42,  0.32, -0.33,\n",
      "         0.89, -0.47,  0.48, -1.39, -0.08, -0.81, -0.62, -1.11,  0.87,  0.19,\n",
      "         0.19, -1.94,  0.79,  0.23], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# deep dive attention calculations\n",
    "x,y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "# print(x[0][:10])\n",
    "# print(y[0][:10])\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "embeddings = nn.Embedding(vocab_size, embed_size).to(device) # eg 4096 x 384\n",
    "positions = nn.Embedding(context, embed_size).to(device) # e.g 512 x 384\n",
    "queries = nn.Linear(embed_size, head_size, bias=BIAS).to(device)\n",
    "keys = nn.Linear(embed_size, head_size, bias=BIAS).to(device)\n",
    "values = nn.Linear(embed_size, head_size, bias=BIAS).to(device)\n",
    "tril = torch.tril(torch.ones(context,context)).to(device)\n",
    "\n",
    "emb = embeddings(x)\n",
    "pos = positions(torch.arange(context, device=device))\n",
    "x = emb + pos\n",
    "\n",
    "q = queries(x)\n",
    "k = keys(x)\n",
    "v = values(x)\n",
    "print(q.shape, k.shape, v.shape)\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "#torch.set_printoptions(precision=4, threshold=1000, edgeitems=3, linewidth=80, profile='default', sci_mode=True)\n",
    "print(q[0][0])\n",
    "\n",
    "attn_w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # BS, SL, SL\n",
    "attn_w = attn_w.masked_fill(tril[:context, :context]==0, float('-inf'))\n",
    "attn_w = F.softmax(attn_w, dim=-1) # BS, SL, SL\n",
    "\n",
    "x = attn_w @ v # BS, SL, 54\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af41d643-1e51-45c3-8dfa-dc41caef3db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.70,  0.98,  0.11, -0.03,  0.24, -0.55,  0.03, -0.06,  0.17, -0.06,\n",
      "         1.18,  0.95,  0.17, -0.93, -0.07,  0.03, -1.21, -0.55, -0.15,  0.36,\n",
      "        -0.19, -0.35, -0.05,  0.81, -1.22,  1.48,  1.48,  0.37,  0.18,  0.60,\n",
      "         0.18,  0.97,  0.10,  0.62, -1.21, -0.61, -0.99,  1.08, -0.97, -1.94,\n",
      "        -1.63,  1.64,  0.54,  0.22, -0.32, -0.66, -0.86, -0.54, -0.11, -0.11,\n",
      "        -0.50, -0.25,  0.98, -2.31], grad_fn=<SelectBackward0>) tensor([ 0.48, -1.19, -0.78, -0.06, -0.91,  0.58,  0.46,  1.25, -1.69, -1.71,\n",
      "         0.24, -1.23, -0.75, -0.82, -0.57, -0.01,  0.81, -0.74, -1.35,  0.36,\n",
      "         0.03,  0.77, -0.90,  0.56,  0.67,  1.26, -1.55, -0.22, -0.31,  0.35,\n",
      "        -1.09,  0.11,  0.11,  0.23,  0.94,  0.98, -1.27,  0.31,  1.37,  0.89,\n",
      "         1.11,  0.20, -0.51, -0.71,  1.00, -0.00,  0.90, -1.37,  0.50, -0.71,\n",
      "         0.21,  0.63,  0.46,  0.51], grad_fn=<SelectBackward0>)\n",
      "tensor(-8.98, grad_fn=<DotBackward0>)\n",
      "tensor(-8.98, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# understand attn matrix\n",
    "\n",
    "full = q @ k.transpose(-2, -1)\n",
    "# compare 5th token to 3rd token in a 54 dim\n",
    "a = q[0][5]\n",
    "b = k.transpose(-2,-1)[0,:,5]\n",
    "print(a,b)\n",
    "c = torch.dot(a,b)\n",
    "# compare the token with the full matrix, comparing the aligment b/w tokens\n",
    "print(c)\n",
    "print(full[0][5][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3944fcc1-442b-4da7-af8b-337805c52c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 512]) torch.Size([8, 512, 54])\n",
      "tensor([-0.04,  0.24,  0.16, -0.27,  0.36,  0.47,  0.35, -0.41, -0.24, -0.58,\n",
      "        -0.05,  0.07,  0.21, -0.06,  0.05,  0.09, -0.27, -0.01,  0.06, -0.15,\n",
      "         0.56, -0.80, -0.08,  0.58, -0.09,  0.51, -0.46, -0.28, -0.37,  0.32,\n",
      "        -0.23, -0.05,  0.54, -0.15,  0.65, -0.22, -0.47, -0.55, -0.13,  0.10,\n",
      "         0.48, -0.18,  0.75, -0.45, -0.26,  0.23,  0.28,  0.21,  0.07, -0.14,\n",
      "         0.34, -0.04,  0.21,  0.07], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.04,  0.24,  0.16, -0.27,  0.36,  0.47,  0.35, -0.41, -0.24, -0.58,\n",
      "        -0.05,  0.07,  0.21, -0.06,  0.05,  0.09, -0.27, -0.01,  0.06, -0.15,\n",
      "         0.56, -0.80, -0.08,  0.58, -0.09,  0.51, -0.46, -0.28, -0.37,  0.32,\n",
      "        -0.23, -0.05,  0.54, -0.15,  0.65, -0.22, -0.47, -0.55, -0.13,  0.10,\n",
      "         0.48, -0.18,  0.75, -0.45, -0.26,  0.23,  0.28,  0.21,  0.07, -0.14,\n",
      "         0.34, -0.04,  0.21,  0.07], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "# understand the updating of the v content (values)\n",
    "print(attn_w.shape, v.shape)\n",
    "\n",
    "print(x[0][7])\n",
    "\n",
    "# check the 7 token\n",
    "attn_scores2 = attn_w[0, 7, :] #shape [512]\n",
    "# initialize tensor to store the result\n",
    "result = torch.zeros(54)\n",
    "# compute the do product for the each column in the v for the first token in the first batch\n",
    "for i in range(54):\n",
    "    result[i] = torch.dot(attn_scores2, v[0,:,i])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60c668ba-f076-429f-8f78-bd9ee9f97ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "tensor([ 653, 1828,  824,  845,  870, 1069, 4031, 4062, 4051,  343])\n",
      "tensor([1828,  824,  845,  870, 1069, 4031, 4062, 4051,  343,  528])\n",
      "8.4375\n"
     ]
    }
   ],
   "source": [
    "x,y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print(x[0][:10])\n",
    "print(y[0][:10])\n",
    "\n",
    "model = GPT()\n",
    "model = model.to(dtype)\n",
    "model = model.to(device)\n",
    "logits, loss = model(x,y)\n",
    "# logits, loss, loss2 = model(x,y)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67847fe6-9c48-4a92-80fa-e6ae8a0f8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " occur box name War kept Christianitive other workingachesince changeask Columb Phil problem comes toiller Michmonddela size education Kentamage Virginiava Super de Sm Indian\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate_sample(input):\n",
    "    t1 = torch.tensor(encode(input), dtype=torch.long, device=device)\n",
    "    t1 = t1[None, :] #(1, [size of the ids])\n",
    "    newgen= model.generate(t1, max=64)[0].tolist()\n",
    "    result=decode(newgen)\n",
    "    print(f\"{result}\")\n",
    "\n",
    "generate_sample(\"Once upon a time\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a3c8a52-0bc6-4e7f-a811-351d4ad2ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.837954 Million parameters\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "\n",
    "model = GPT()\n",
    "model = model.to(dtype)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "if compile:\n",
    "    print(\"torch :: compiling model\")\n",
    "    model = torch.compile(model)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, \"Million parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82475128-1ac0-46cc-bcb7-1a2af75ba63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "{'train': 8.4375, 'eval': 8.4375}\n"
     ]
    }
   ],
   "source": [
    "# calculate loss average\n",
    "@torch.no_grad()\n",
    "def calculate_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train','eval']:\n",
    "        l = torch.zeros(eval_iteration)\n",
    "        for i in range(eval_iteration):\n",
    "            x,y = get_batch(split)\n",
    "            _,loss = model(x,y)\n",
    "            l[i]=loss\n",
    "        out[split]=l.mean().item()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "l = calculate_loss()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f797629-aa86-4866-bdaf-33baccc4f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the optimizer\n",
    "\n",
    "p_dict = {p_name: p for p_name, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "weight_decay_p = [p for n,p in p_dict.items() if p.dim() >=2]\n",
    "no_weight_decay_p = [p for n,p in p_dict.items() if p.dim() < 2]\n",
    "\n",
    "optimizer_groups = [\n",
    "    {'params':weight_decay_p,'weight_decay':weight_decay},\n",
    "    {'params':no_weight_decay_p,'weight_decay':0.0},\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_groups, lr=lr, betas=(0.9, 0.99))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, train_iters, eta_min=lr/10)\n",
    "\n",
    "start_iteration = 0\n",
    "best_val_loss = float('inf') # track the validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8faf3adf-6789-49b8-8301-00627feb4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading checkpoints\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    print(\"LLM - Loading model\")\n",
    "    # Add map_location parameter to load the model on CPU\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    iteration = checkpoint['iteration']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"loaded iter {iteration} with loss {loss}\")\n",
    "    return iteration, loss\n",
    "\n",
    "if os.path.exists(f\"{checkpoint_dir}/{checkpoint_load_fn}\") and load_pretrained:\n",
    "    start_iteration, loss = load_checkpoint(checkpoint_dir+checkpoint_load_fn)\n",
    "    best_val_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4456e476-5602-4833-a999-4bd5d822ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "if inference == True:\n",
    "    model.eval()\n",
    "    while True:\n",
    "        qs = input(\"Enter text (q to quit):\")\n",
    "        if qs == \"\":\n",
    "            continue\n",
    "        if qs == \"q\":\n",
    "            break\n",
    "        generate_sample(qs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed5505ee-69e6-41bb-a18e-15bcee448df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "[loss diff] pytorch:8.4375 Manual:8.375\n",
      "\n",
      "0: train loss: 8.4375/ val loss: 8.4375\n",
      "Once upon a time causedersey pain regionher port Rob Jer Jr overouncada Don Pakistan Marthy school that mer community common mag muchransynasty British Cle problemsological occur neededatives just skin housir using Russia ratherme contro known partic askound story Wrestore published Minn tr campW minister center Alsoionalrdella Christian Soviet blue\n",
      "[Checkpoint]: save with loss:  8.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                | 0/100000 [17:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory released\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saakla/miniconda/envs/llmdemo/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(start_iteration, train_iters)):\n",
    "        xb, yb = get_batch(\"train\")\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "        if (i % eval_interval == 0 or i == train_iters-1):\n",
    "            l = calculate_loss()\n",
    "            print(f\"\\n{i}: train loss: {l['train']}/ val loss: {l['eval']}\")\n",
    "            generate_sample(\"Once upon a time\")\n",
    "\n",
    "            if l['eval'] < best_val_loss:\n",
    "                best_val_loss = l['eval']\n",
    "                print(\"[Checkpoint]: save with loss: \", best_val_loss)\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss' : best_val_loss,\n",
    "                    'iteration': i,\n",
    "                }, checkpoint_dir + checkpoint_fn)\n",
    "\n",
    "\n",
    "            if wandb_log:\n",
    "                wandb.log({\n",
    "                    \"loss/train\":l['train'],\n",
    "                    \"loss/val\" : l['eval'],\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                },\n",
    "                step = i)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=grap_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "\n",
    "    if wandb_log:\n",
    "        wandb.finish()\n",
    "\n",
    "except keyboardInterrupt:\n",
    "    print(\"training interrupted, cleaning up..\")\n",
    "\n",
    "finally:\n",
    "    # release gpu memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU memory released\")\n",
    "    sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a47573-9ee5-40a2-8e6b-51bc0b4a1a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
